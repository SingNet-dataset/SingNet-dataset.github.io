<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Emilia Demo Page</title>
  <script src="./static/tailwind.js"></script>
  <script src="./static/vue.global.js"></script>
  <script src="./static/flowbite.min.js"></script>
  <script src="./static/d3.v7.min.js"></script>
  <style type="text/tailwindcss">
    @tailwind base;
    @tailwind components;
    @tailwind utilities;

    @layer base {
      a[href^="http"] {
        @apply text-blue-500;
      }

      a:hover {
        @apply text-blue-700 underline;
      }

      h1 {
        @apply mb-6 text-4xl font-bold text-gray-900 dark:text-white text-center;
      }

      h4 {
        @apply mb-4 pt-12 text-3xl font-semibold text-gray-900 dark:text-white;
      }

      h5 {
        @apply mb-3 pt-4 text-2xl font-bold tracking-tight text-gray-900 dark:text-white;
      }

      p {
        @apply mb-4 font-normal text-gray-900 dark:text-gray-400 leading-relaxed;
      }
    }

    @layer components {
      .list-select {
        @apply block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent;
      }

      .tooltip {
        position: absolute;
        text-align: center;
        padding: 8px;
        font: 12px sans-serif;
        background: lightsteelblue;
        border: 0;
        border-radius: 8px;
        pointer-events: none;
        opacity: 0;
      }

      .text-p {
        @apply mb-4 font-normal text-gray-900 dark:text-gray-400 leading-relaxed;
      }

      .author {
        @apply font-medium mr-2 pb-1 text-gray-900 dark:text-gray-400 inline-block;
      }

      .affiliation {
        @apply font-medium mr-2 pb-1 text-gray-900 dark:text-gray-400 block;
      }
    }
  </style>

  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {}
        }
      }
    }
  </script>
</head>

<body class="dark:bg-gray-900">
  <div id="app">

    <nav
      class="bg-white fixed w-full z-20 top-0 start-0 border-gray-200 dark:bg-gray-900 border-b border-gray-200 dark:border-gray-600">
      <div class="max-w-screen-xl flex flex-wrap items-center justify-between mx-auto p-3">
        <button data-collapse-toggle="navbar-default" type="button"
          class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600"
          aria-controls="navbar-default" aria-expanded="false">
          <span class="sr-only">Open main menu</span>
          <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14">
            <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
              d="M1 1h15M1 7h15M1 13h15" />
          </svg>
        </button>

        <div class="hidden w-full md:block md:w-auto ml-auto" id="navbar-default">
          <ul
            class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50 md:flex-row md:space-x-8 rtl:space-x-reverse md:mt-0 md:border-0 md:bg-white dark:bg-gray-800 md:dark:bg-gray-900 dark:border-gray-700">
            <li>
              <a href="#home" class="list-select">Home</a>
            </li>
            <li>
              <a href="#dataset" class="list-select">Dataset</a>
            </li>
            <li>
              <a href="#pipeline" class="list-select">Pipeline</a>
            </li>
            <li>
              <a href="#demos" class="list-select">Demos</a>
            </li>
            <li>
              <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia" class="list-select" target="_blank">
                <svg class="w-6 h-6 text-gray-900 hover:text-blue-700" aria-hidden="true"
                  xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24">
                  <path fill-rule="evenodd"
                    d="M12.006 2a9.847 9.847 0 0 0-6.484 2.44 10.32 10.32 0 0 0-3.393 6.17 10.48 10.48 0 0 0 1.317 6.955 10.045 10.045 0 0 0 5.4 4.418c.504.095.683-.223.683-.494 0-.245-.01-1.052-.014-1.908-2.78.62-3.366-1.21-3.366-1.21a2.711 2.711 0 0 0-1.11-1.5c-.907-.637.07-.621.07-.621.317.044.62.163.885.346.266.183.487.426.647.71.135.253.318.476.538.655a2.079 2.079 0 0 0 2.37.196c.045-.52.27-1.006.635-1.37-2.219-.259-4.554-1.138-4.554-5.07a4.022 4.022 0 0 1 1.031-2.75 3.77 3.77 0 0 1 .096-2.713s.839-.275 2.749 1.05a9.26 9.26 0 0 1 5.004 0c1.906-1.325 2.74-1.05 2.74-1.05.37.858.406 1.828.101 2.713a4.017 4.017 0 0 1 1.029 2.75c0 3.939-2.339 4.805-4.564 5.058a2.471 2.471 0 0 1 .679 1.897c0 1.372-.012 2.477-.012 2.814 0 .272.18.592.687.492a10.05 10.05 0 0 0 5.388-4.421 10.473 10.473 0 0 0 1.313-6.948 10.32 10.32 0 0 0-3.39-6.165A9.847 9.847 0 0 0 12.007 2Z"
                    clip-rule="evenodd" />
                </svg>    
              </a>
            </li>
            <li>
              <a href="https://huggingface.co/datasets/amphion/Emilia-Dataset" class="list-select" target="_blank">
                <img class="h-6 w-6" src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg"/> 
              </a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="p-5 md:p-0 mt-16 max-w-screen-xl mx-auto">
      <div class="p-6" id="home">

        <div class="mt-8 mb-8">
          <h1>Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation</h1>
        </div>

        <div class="flex gap-2 justify-center flex-wrap">
          <a href="https://arxiv.org/abs/2407.05361" target="_blank">
            <img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg">
          </a>
          <a href="https://huggingface.co/datasets/amphion/Emilia-Dataset" target="_blank">
            <img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow">
          </a>
          <a href="https://opendatalab.com/Amphion/Emilia" target="_blank">
            <img src="https://img.shields.io/badge/OpenDataLab-Dataset-blue">
          </a>
          <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia" target="_blank">
            <img src="https://img.shields.io/badge/GitHub-Repo-green">
          </a>
          <a href="https://emilia-dataset.github.io/Emilia-Demo-Page/" target="_blank">
            <img src="https://img.shields.io/badge/WebPage-Demo-red">
          </a>
        </div>

        <div class="max-w-[900px] mx-auto mt-8 mb-16">
          <div class="text-center pb-10 flex flex-col gap-3">
            <div class="text-sm">
              <span class="author">Haorui He<sup>1,★</sup> </span>
              <span class="author">Zengqiang Shang<sup>2,★</sup> </span>
              <span class="author">Chaoren Wang<sup>1,★</sup> </span>
              <span class="author">Xuyuan Li<sup>2,3,★</sup></span>
              <span class="author">Yicheng Gu<sup>1</sup> </span>
              <span class="author">Hua Hua<sup>2,3</sup> </span>
              <span class="author">Liwei Liu<sup>1</sup> </span>
              <span class="author">Chen Yang<sup>2,3</sup> </span>
              <span class="author">Jiaqi Li<sup>1</sup> </span>
              <span class="author">Peiyang Shi<sup>2</sup></span>
              <span class="author">Yuancheng Wang<sup>1</sup> </span>
              <span class="author">Kai Chen<sup>4</sup> </span>
              <span class="author">Pengyuan Zhang<sup>2,3,‡</sup> </span>
              <span class="author">Zhizheng Wu<sup>1,4,‡</sup></span>
            </div>
            <div class="text-sm">
              <span class="affiliation"><sup>1</sup> The Chinese University of Hong Kong, Shenzhen, China</span>
              <span class="affiliation"><sup>2</sup> Laboratory of Speech & Intelligent Information Processing, Institute of Acoustics, CAS, China</span>
              <span class="affiliation"><sup>3</sup> University of Chinese Academy of Sciences, Beijing, China</span>
              <span class="affiliation"><sup>4</sup> Shanghai AI Laboratory, Shanghai, China</span>
            </div>
            <div class="text-sm">
              <span class="author"><sup>★</sup> Equal contribution, and the names are listed in random order.</span>
              <span class="author"><sup>‡</sup> Corresponding authors.</span>
            </div>
          </div>
          <h5>Abstract</h5>
          <p class="text-p">
            Recent advancements in speech generation models have been significantly driven by the use of large-scale
            training data. However, producing highly spontaneous, human-like speech remains a challenge due to the
            scarcity of large, diverse, and spontaneous speech datasets. In response, we introduce <code>Emilia</code>,
            the first
            large-scale, multilingual, and diverse speech generation dataset. Emilia starts with over 101k hours of
            speech across six languages, covering a wide range of speaking styles to enable more natural and spontaneous
            speech generation. To facilitate the scale-up of Emilia, we also present <code>Emilia-Pipe</code>, the first
            open-source
            preprocessing pipeline designed to efficiently transform raw, in-the-wild speech data into high-quality
            training data with speech annotations. Experimental results demonstrate the effectiveness of both Emilia and
            Emilia-Pipe. Demos are available at: <a
              href="https://emilia-dataset.github.io/Emilia-Demo-Page/">https://emilia-dataset.github.io/Emilia-Demo-Page/</a>.
          </p>
        </div>

        <h4 id="dataset">The Emilia Dataset</h4>

        <h5 id="dataset-overview">Overview</h5>
        <p class="text-p">
          The <code>Emilia</code> dataset is constructed from a vast collection of speech data sourced from diverse
          video platforms and podcasts on the Internet, covering various content genres such as talk shows, interviews,
          debates, sports commentary, and audiobooks. This variety ensures the dataset captures a wide array of real
          human speaking styles. The initial version of the Emilia dataset includes a total of 101,654 hours of
          multilingual speech data in six different languages: English, French, German, Chinese, Japanese, and Korean.
          The table and chart below provide the duration statistics for each language in the dataset.
        </p>

        <div class="my-4 grid grid-cols-1 mx-auto max-w-screen-sm md:grid-cols-2">
          <div class="relative overflow-x-auto mx-auto">
            <div class="relative w-fit text-sm text-left rtl:text-right text-gray-900 dark:text-gray-200">
              <div class="flex w-full text-center text-gray-900 bg-gray-50 dark:bg-gray-700 dark:text-gray-300">
                <div v-for="(item, index) in ['Lang.', 'Duration (hours)']" scope="col"
                  :class="(index == 0 ? 'w-[80px]' : 'w-[200px]') + ' shrink-0 px-6 py-4 font-bold'">
                  {{ item }}
                </div>
              </div>

              <div v-for="(item, index) in data"
                class="flex w-full text-center bg-white border-b dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                <div v-for="(value, index) in Object.values(item)"
                  :class="(index == 0 ? 'w-[80px]' : 'w-[200px]') + ' px-4 py-2'">
                  {{ value.toLocaleString("en-US") }}
                </div>
              </div>
            </div>
          </div>

          <div class="w-[280px] h-[280px] flex mx-auto">
            <img src="./static/emilia_data.svg"></img>
          </div>
        </div>

        <p class="text-p">
          The figure below compares the acoustic and semantic diversities between Emilia and MLS datasets, which is
          sourced from audiobooks. The more scattered pattern highlights the Emilia dataset as encompassing a richer
          acoustic characteristic and semantic coverage compared to the existing audiobook dataset.
        </p>

        <div class="w-full">
          <img class="mx-auto max-h-[280px]" src="./static/diversity.png"></img>
        </div>

        <h5>Data Preview</h5>
        <p class="text-p">
          To better understand the performance of the pipeline as well as the diversity and quality of the dataset, we
          have sampled a few speech examples below for preview.
        </p>

        <!-- data_pipeline_egs:table -->
        <div class="w-full overflow-x-auto">
          <div class="relative w-fit mx-auto text-sm text-left rtl:text-right text-gray-900 dark:text-gray-100">
            <!-- body -->
            <div v-for="(item, index) in data_pipeline_egs">
              <div
                class="flex bg-white border-b dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                <div class="w-[100px] px-6 h-full my-auto font-bold dark:text-white">{{ item.name }}</div>
                <div v-for="path in item.path" class="w-[310px] px-4 py-2">
                  <audio controls>
                    <source :src="'data/pipeline_egs/' + path">
                  </audio>
                </div>
              </div>
            </div>
          </div>
        </div>

        <h4 id="pipeline">The Emilia-Pipe Preprocessing Pipeline</h4>
        <p class="text-p">
          <code>Emilia-Pipe</code> is the first open-source preprocessing pipeline designed to transform in-the-wild
          speech data into high-quality training data with annotations for speech generation. It consists of six major
          steps: Standardization, Source Separation, Speaker Diarization, Fine-grained Segmentation by VAD, ASR, and
          Filtering. The figure below provides an overview of the Emilia-Pipe.
        </p>

        <div class="flex mx-auto justify-center max-w-screen-lg py-8">
          <img src="./static/emilia_pipe.svg"></img>
        </div>

        <p class="text-p">
          After processing, the Emilia-Pipe outputs the speech data in JSON and MP3 format. The JSON file contains
          metadata such as language, and transcription, while the MP3 file contains the speech data. The JSON file is
          structured as follows:
        </p>

        <div class="flex mx-auto justify-center max-w-screen-lg py-6">
          <img class="min-h-[160px]" src="./static/json_example.svg"></img>
        </div>

        <!-- <p class="text-p">
          The source code for Emilia-Pipe is available here: <a class="text-blue-500"
            href="https://github.com/open-mmlab/Amphion">open-mmlab/Amphion</a>.
        </p> -->


        <h4 id="demos">Demos</h4>
        <p class="text-p">
          In this section, we demonstrate the zero-shot TTS performance of the models (Soundstorm and VoiceBox) trained
          on Emilia.
        </p>

        <h5 id="multilingual-samples">Samples generated by models trained with the full Emilia (101k hours) multilingual
          dataset.</h5>

        <!-- data_multilingual_egs:table -->
        <div class="w-full overflow-x-auto my-4">
          <div class="relative  w-[1026px] mx-auto text-sm text-left rtl:text-right text-gray-900 dark:text-gray-100">
            <div class="flex text-center bg-gray-50 dark:bg-gray-700">
              <div v-for="item in [{name: 'Language', width: 126}, ...data_multilingual_egs_sounds]" scope="col"
                :class="'w-[' + (item.width ?? 300) +'px] shrink-0 px-6 py-4 font-bold'">{{
                item.name }}</div>
            </div>

            <!-- body -->
            <div v-for="(lang_egs, index) in data_multilingual_egs">
              <div
                class="flex w-full bg-white dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                <div
                  class="shrink-0 border-b w-[126px] flex px-6 py-4 font-bold justify-center items-center dark:text-white">
                  {{
                  lang_egs.name }}</div>

                <div>
                  <div v-for="item in lang_egs.items">
                    <div
                      class="flex bg-white dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                      <div class="ml-[280px] px-6 py-4 font-base dark:text-white"><b>Target Text:</b> {{
                        item.targetText
                        }}
                      </div>
                    </div>
                    <div
                      class="flex bg-white border-b dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                      <div v-for="sound in data_multilingual_egs_sounds" class="w-[300px] px-4 py-2">
                        <audio controls class="mx-auto w-[280px]" controlsList="nodownload noremoteplayback">
                          <source :src="'data/multilingual_egs/' + lang_egs.path + '/' + item.path + '/' + sound.path">
                        </audio>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>

          </div>
        </div>

        <h5 id="en-samples">Samples generated by models trained on the English subset of Emilia and MLS respectively.
        </h5>

        <!-- data_model_egs:table -->
        <div class="w-full overflow-x-auto my-4">
          <div class="relative w-fit mx-auto text-sm text-left rtl:text-right text-gray-900 dark:text-gray-100">
            <div class="flex w-fit text-center bg-gray-50 dark:bg-gray-700">
              <div v-for="item in data_model_egs_sounds" scope="col" class="w-[260px] shrink-0 px-6 py-4 font-bold">{{
                item.name }}</div>
            </div>

            <!-- body -->
            <div v-for="(item, index) in data_model_egs">
              <div
                class="flex w-full bg-white dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                <div class="ml-[260px] px-6 py-4 font-base dark:text-white"><b>Target Text:</b> {{ item.targetText }}
                </div>
              </div>
              <div
                class="flex bg-white border-b dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                <div v-for="sound in data_model_egs_sounds" class="w-[260px] px-4 py-2">
                  <audio controls class="w-[250px]" controlsList="nodownload noremoteplayback">
                    <source :src="'data/model_egs/' + item.path + '/' + sound.path">
                  </audio>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script>
    const app = Vue.createApp({
      setup() {
        const data = [
          { lang: 'En', duration: 46828 },
          { lang: 'Zh', duration: 49922 },
          { lang: 'De', duration: 1590 },
          { lang: 'Fr', duration: 1381 },
          { lang: 'Ja', duration: 1715 },
          { lang: 'Ko', duration: 217 }
        ];

        const data_pipeline_egs = [
          {
            name: "English",
            path: [
              "en_1.mp3",
              "en_3.mp3",
            ]
          },
          {
            name: "Chinese",
            path: [
              "zh_1.mp3",
              "zh_3.mp3",
            ]
          },
          {
            name: "German",
            path: [
              "de_1.mp3",
              "de_2.mp3",
            ]
          },
          {
            name: "French",
            path: [
              "fr_1.mp3",
              "fr_2.mp3",
            ]
          },
          {
            name: "Japanese",
            path: [
              "ja_1.mp3",
              "ja_2.mp3",
            ]
          },
          {
            name: "Korean",
            path: [
              "ko_1.mp3",
              "ko_2.mp3",
            ]
          },
        ]

        const data_model_egs_sounds = [
          {
            name: "Speech Prompt",
            path: "ref.wav"
          },
          {
            name: "SoundStorm-Emilia",
            path: "ar_emilia.wav"
          },
          {
            name: "SoundStorm-MLS",
            path: "ar_mls.wav"
          },
          {
            name: "VoiceBox-Emilia",
            path: "nar_emilia.wav"
          },
          {
            name: "VoiceBox-MLS",
            path: "nar_mls.wav"
          },
        ]

        const data_multilingual_egs_sounds = [
          {
            name: "Speech Prompt",
            path: "ref.wav"
          },
          {
            name: "SoundStorm",
            path: "ss.wav"
          },
          {
            name: "VoiceBox",
            path: "vb.wav"
          }
        ]

        const data_model_egs = [
          {
            path: "ss_1",
            targetText: "Probably. I mean, but at nine dollars a piece, we don't want to see too many doubles today. What do we have here? Another dog.",
          },
          {
            path: "ab_2",
            targetText: "\"Then, dear,\" said Mrs. Whitney, \"you must be kinder to her than ever; think what it would be for one of you to be away from home even among friends.\"",
          },
          {
            path: "ss_2",
            targetText: "And then it's those two thick long things are connected to a thicker thing down there. And then it has these",
          },
        ]

        const data_multilingual_egs = [
          {
            name: "English",
            path: "en",
            items: [
              {
                path: "1",
                targetText: "Dealing with family secrets is never easy. Yet, sometimes, omission is a form of protection, intending to safeguard some from the harsh truths. One day, I hope you understand the reasons behind my actions. Until then, Anna, please, bear with me"
              },
              {
                path: "2",
                targetText: "I don't really care what you call me. I've been a silent spectator, watching species evolve, empires rise and fall. But always remember, I am mighty and enduring. Respect me and I'll nurture you; ignore me and you shall face the consequences."
              }
            ]
          },
          {
            name: "Chinese",
            path: "zh",
            items: [
              {
                path: "1",
                targetText: "突然，身边一阵笑声。我看着他们，意气风发地挺直了胸膛，甩了甩那稍显肉感的双臂，轻笑道：\"我身上的肉，是为了掩饰我爆棚的魅力，否则，岂不吓坏了你们呢？\""
              },
              {
                path: "2",
                targetText: "气氛变得沉郁起来。乍看之下，一切的困扰仿佛都围绕在我身边。我皱着眉头，感受着那份压力，但我知道我不能放弃，不能认输。于是，我深吸一口气，心底的声音告诉我：“无论如何，都要冷静下来，重新开始。”"
              }
            ]
          },
          {
            name: "German",
            path: "de",
            items: [
              {
                path: "2",
                targetText: "Er ist damit in der Geschichte des Gerichts der bisher einzige Richter aus Kanada."
              },
              {
                path: "1",
                targetText: "Der Film bedeutete den Durchbruch der Steadicam."
              },
            ]
          },
          {
            name: "French",
            path: "fr",
            items: [
              {
                path: "2",
                targetText: "Connu comme grand buveur depuis longtemps, il sombre dans l’alcoolisme."
              },
              {
                path: "1",
                targetText: "Il est le, principal traducteur de la Bible en tahitien."
              },
            ]
          },
          {
            name: "Japanese",
            path: "ja",
            items: [
              {
                path: "1",
                targetText: "ここに物を置いてはいけません"
              },
              {
                path: "2",
                targetText: "答えを書いた紙を出してください"
              }
            ]
          },
          {
            name: "Korean",
            path: "ko",
            items: [
              {
                path: "1",
                targetText: "하나님이 주셔서 나와 함께하게 하신 여자"
              },
              {
                path: "2",
                targetText: "내가 너로 여자와 원수가 되게하고 너의 후손도 여자의 후손과 원수가 되게 하리니"
              }
            ]
          },
        ]

        return {
          data_pipeline_egs,
          data_model_egs_sounds,
          data_multilingual_egs_sounds,
          data_model_egs,
          data_multilingual_egs,
          data
        }
      }
    })

    app.mount('#app')
  </script>
</body>

</html>